# Design Notes

This file documents the current state of, and some of the rationale behind, the
design.  Not all the choices here are necessarily optimal and are certainly not
written in stone, even those with a solid rationale.  It is expected that the
right design reveals itself as the work goes on.

## General Principles

Throughout the design, an effort was made to capture useful distinctions with
static type information where possible.  For example, `Pattern`s,
`TypeExpression`s, and `Expression`s are represented by distinct types, even
though there is significant overlap between them.  The idea is to leave
guideposts that make the code more understandable and easier to work on.

We've also tried to ensure that executable semantics implementors can't easily
and unknowingly do things that don't translate into an AOT compiler.  For
example, while values in the interpreter carry their types, it's named
`dynamic_type` rather than, simply, `type`, to prevent it from being used to
implement constructs that should only depend on static type information.

## Architecture

The system is primarily built in phases that (with one exception) are simple
sequential dependencies:

1. Lexical analysis (Scanner.swift, Token.swift, SourceRegion.swift)
2. Parsing (Parser.citron, AST.swift)
3. Name resolution (Name Resolution.swift), which associates uses of 
   identifiers with declarations.
4. Type checking (TypeChecker.swift, Type.swift, Value.swift)
5. Interpretation (Interpreter.swift, Memory.swift)

The one exception to the phase ordering is that the type checker uses the
interpreter to evaluate compile-time expressions, including types.  This
dependency inversion can be disabled, with a corresponding diminishment of
language capability, by compiling with `-DNO_COMPILE_TIME_COMPUTE` (or by
editing the source where `NO_COMPILE_TIME_COMPUTE` appears in
TypeChecker.swift).  That may be useful for debugging/analysis of problems in
programs that don't require significant compile-time computation.

Phase 1-4 are captured in the initializer of `ExecutableProgram` a type that
contains all the data needed by the interpreter to run the program.

### Lexical Analysis

The scanner is not production-performance because it uses regular expressions,
but “should” otherwise be totally solid. It should eventually be [contributed
back](https://github.com/roop/citron/issues/12) to the
[Citron](http://roopc.net/citron/) project that supplies the parser generator,
but whose lexer does not obey the max-munch rule (and performs even worse).  The
top part of Scanner.swift contains the high-level specification of token
patterns, and is all anybody should have to edit in order to change the tokens
of the Carbon language.

The scanner counts characters (Unicode grapheme clusters) and newlines to track
the start and end position of each token recognized. That range, along with a
filename, is captured in a `SourceRegion`, which is used for diagnostics, and to
uniquely identify AST nodes (see the Parsing section).

### The AST

The AST (AST.swift) generated by the parser is the central data structure on
which everything except lexical analysis depends, so is key for understanding
the rest of the system.

#### Immutability and property maps

Semantic analysis (name lookup, type checking, etc.) traditionally means
annotating an AST with additional information (e.g. types), and often, rewriting
the AST into equivalent but more expressive forms.  Because the AST is a value
type, I didn't worry that mutation would create “spooky action at a distance”
problems.  Nonetheless, it ended up never being mutated because the need for
annotation creates an uncomfortable engineering choice to either:
1. Give the nodes optional parts that would be a) missing and thus invalid to
   access, and b) irrelevant and thus distracting, in earlier phases of
   processing.
2. Or, create additional “enhanced” node types to represent the parsing
   information plus annotations, leaving us with the prospect of `Identifier`,
   `IdentifierAfterNameLookup` and `IdentifierAfterTypeChecking`.

Instead, the system uses the idea of “property maps”—developed for the Boost
Graph Library—to store annotations.  The concept is to take data that you might
otherwise store internally to a data structure, such as an AST node's type or a
graph vertex's color, and put it in a data structure like a dictionary or array,
where it can be looked up by the identity of the thing with which it is
associated.

So, currently, the AST is never mutated once constructed, and the phases of
translation are responsible for adding annotation information to property maps.
The phases also use property maps as part of their internal processing; these
are generally private properties that are discarded when the phase is complete.

#### Node Equality and Identity

The AST representation uses Swift enums and `struct`s, which are all value
types, like `Int` or `std::vector` in C++ (but with lazy COW for deep data).  In
safe Swift, a value doesn't have an identity; you can only differentiate two
values based on their contents. Since, e.g. `var x: auto` can appear multiple
times in a Carbon program, each one meaning something different, we need some
way to tell the difference between two AST nodes with identical contents.

The current approach is to use the range of source text plus the node type as a
unique identifier.  This works because if node types correspond to grammar
symbols, two distinct nodes having the same type and source region is
impossible—it would imply the parser is in an infinite loop.  So node identity
is based on location.

Node *equality*, though, is based on content/structure, not location.  That
allows us to check whether two `Identifier`s have the same name with simple
equality and use them as hash keys, and to cleanly test that the parser gives
expected results.

To allow Swift to synthesize `Equatable` conformance for AST nodes without
involving the value of a stored `SourceRegion`, they instead store `ASTSite`
instances, which wrap `SourceRegion`s, but whose instances are all equal,
regardless of content.

There are two first-class representations of node identity: `ASTIdentity<Node>`,
which carries the node type as part of its type, and `AnyASTIdentity`, for which
the node type is stored dynamically.  The latter is useful for storing the
identities of nodes with heterogeneous types, such as declarations, the former
for keeping code on the straight-and-narrow when the node type is known
statically.  Both representations expose the identified node's content through a
`structure` property.

All AST nodes conform to the `AST` protocol, which is just an `Equatable` thing
annotated with a `site` in the Carbon source code.  `AST` categories such as
`Declaration`, that cut across the distinct concrete types in the `AST`, are
represented as protocols that are used as (existential) types.

In summary, the key types and protocols of the AST are:
- `AST`: All AST node types.
- `AbstractSyntaxTree`: a typealias for the type that describes the parser
  output.
- `Declaration`, `TypeDeclaration`: cross-cutting AST node categories; used as
  existentials.
- `ASTSite`: A wrapper over `SourceRegion` that hides its value from Swift's
  synthesis of `Equatable` conformance for nodes that store their own site in
  carbon source.
- `ASTIdentity<Node>`, `AnyASTIdentity`: Representations of an AST node's
  identity that can be used as dictionary keys.

#### ASTDictionary

`ASTDictionary<Node, Value>` is a thin wrapper over
`Dictionary<ASTIdentity<Node>, Value>` that looks `Value`s up by node identity
but is subscripted with a `Node n` rather than `n.identity`, just to keep code
clean.  It is used as a property map, where practical, throughout the implementation.

### Parsing

We use the [Citron](http://roopc.net/citron/) parser generator, which is derived
from the widely-ported [Lemon](https://www.hwaci.com/sw/lemon/lemon.html).  The
parser's only jobs are to validate syntax and build an AST.  The AST node types
were chosen to correspond very closely to grammar symbols, so nearly all parse
rules one-liners.  Lists, however, are represented by arrays for brevity and
ease of later processing, rather than by a linked/nested structure that reflects
how they are parsed.

### Name Resolution

Name resolution has three jobs:

1. Associate each use of an `Identifier` with the definition it names.
2. Identify which variable definitions are global.
3. Report errors for any names defined twice the same scope.

Step two is not strictly part of name resolution, but the result is needed by
the `Interpreter` and it saves lots of complexity to do it here. Name resolution
is order-independent, because it can be, and because any ordering requirements
placed on users should be a product of conscious design decisions and not pure
implementation artifacts.

All the work gets done in the initializer of `NameResolution`.  Property maps
and errors are collected in properties of the created instance.  The source is
divided into rough functional groups by doc-commented `extension`s.

### Type Checking

`TypeChecker` has a similar structure to that of `NameResolution`, described
just above.  The computed types of names and expressions are memoized in
property maps so that checking can proceed in an order dictated by the needs of
the Carbon code, and so that dependency cycles can be detected, without
repeating work. These types are also used by the interpreter when evaluating
code.
